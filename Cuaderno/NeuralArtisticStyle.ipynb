{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Entrenamiento de una Red Neuronal para el Reconocimiento de Imágenes\n",
    "\n",
    "Como muchos saben, **Deep Learning** está tomando mucha importancia hoy en día, siendo sin lugar a dudas uno de los campos del aprendizaje de máquina más popular. Este puede ser entendido como un grupo de algoritmos que fueron desarrollados para entrenar redes neuronales con muchos niveles de una manera muy eficiente. En este trabajo se desarrollará el concepto básico de las redes neuronales y se cubrirá los siguientes puntos:\n",
    "\n",
    "* Concepto de una red neuronal multi-capa.\n",
    "* Entrenar redes neuronales para la clasificación de imágenes.\n",
    "* Implementacón del algoritmo Backpropagation.\n",
    "* Debugging de las implementaciones de una red neuronal.\n",
    "\n",
    "En la última década, muchas más mejoras han sido descubiertas dentro de los algoritmos de Deep Learning, los cuales pueden para crear detectores para los datos usados para entrenar redes neuronales profundas, que están compuestas por muchas capas.\n",
    "\n",
    "### Red Neuronal de una sola capa (Algoritmo ADALINE)\n",
    "\n",
    "![Adaline](imagenes/1Capa.png \"Adaline\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "#los valores de retorno se guardan dentro del objeto perceptron\n",
    "class Perceptron(object):\n",
    "    def __init__(self, eta=0.01, n_iter=10):\n",
    "        self.eta = eta\n",
    "        self.n_iter = n_iter\n",
    "\n",
    "    def entrenar_perceptron(self, X, y):\n",
    "        self.w_ = np.zeros(1 + X.shape[1])\n",
    "        self.errors_ = []\n",
    "\n",
    "        for _ in range(self.n_iter):\n",
    "            errors = 0\n",
    "            for xi, target in zip(X, y):\n",
    "                update = self.eta * (target - self.prueba_perceptron(xi))\n",
    "                self.w_[1:] += update * xi\n",
    "                self.w_[0] += update\n",
    "                errors += int(update != 0.0)\n",
    "            if errors==0.0:\n",
    "                break\n",
    "            self.errors_.append(errors)\n",
    "        return self\n",
    "\n",
    "    def net_input(self, X):\n",
    "        return np.dot(X, self.w_[1:]) + self.w_[0]\n",
    "\n",
    "    def prueba_perceptron(self, X):\n",
    "        return np.where(self.net_input(X) >= 0.0, 1, -1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Introducción a una red neuronal multi-capa (MLP)\n",
    "La siguiente figura explica el concepto de una MLP que consist en 3 capas: una capa de entrada, una capa escondida, y una capa de salida. Las unidades en las capas escondidas están totalmente conectadas con la capa de entrada, y la capa de salida está totalmente conectada con la capa escondida. Si una red tiene más de 1 capa escondida, la llamaremos red neuronal profunda.\n",
    "\n",
    "![MLP](imagenes/3Capas.png \"MLP\")\n",
    "\n",
    "#### Forward propagation\n",
    "Resumiendo el aprendizaje de un MLP:\n",
    "* Comienza con la capa de entrada, donde se propaga los patrones de los datos de entrenamiento a trav[es de la red para generar un resultado.\n",
    "* Basado en el resultado de la red, calculamos el error que se quiere minimizar usando una función de costo que se describirá luego.\n",
    "* Se propaga el error, se encuentra la diferencia con respecto a cada peso en la red, y se actualiza el modelo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Red Neuronal Convolucional (CNNs)\n",
    "\n",
    "Son las responsables de la mayoría de los avances en reconocimiento de imágenes hechos en los últimos años.\n",
    "\n",
    "* Implementación de un CNN simple.\n",
    "* Implementación de un CNN avanzado.\n",
    "* Re-entrenamiento de un modelo existente CNN.\n",
    "\n",
    "#### Introducción:\n",
    "\n",
    "En matemáticas, una convolución es una función, la cual es aplicada sobre el resultado de otra función. En nuestro caso, nosotros consideraremos aplicar una multiplicación de matrices (filtro) sobre una imagen.\n",
    "\n",
    "![Convolution](imagenes/Convolution.png \"Convolution\")\n",
    "\n",
    "Las redes neuronales convolucionales también tienen otras operaciones que cumplen otras necesidades, como introducir no linealidades (ReLU), o agregar parámetros (maxpool), y otras operaciones similares. La imagen anterior es un ejemplo de aplicar la operación de convolución en una matrix 5x5 con un filtro convolucional de dimensión 2x2. El tamaño del paso es 1 y solo consideramos ubicaciones válidas. Las variables entrenables en esta operación serían los pesos de filtro de 2x2.\n",
    "Después de una convolución, es común hacer un seguimiento con un agregado, llamado maxpool. El siguiente diagrama proporciona un ejemplo de cómo opera maxpool:\n",
    "\n",
    "![Maxpool](imagenes/Maxpool.png \"Maxpool\")\n",
    "\n",
    "Es común tomar una red pre-entrenada y re-entrenarla con un nuevo conjunto de datos junto a una capa completamente conectada al final. Este método es muy beneficioso.\n",
    "\n",
    "#### Re-entrenar modelos CNNs\n",
    "\n",
    "Entrenar un nuevo reconocedor de imágenes desde cero, requiere mucho tiempo y poder de computo. Si nosotros tomamos una red entrenada y la re-entrenamos con nuestras imágenes, esto puede ahorrarnos tiempo de cómputo. La idea es reusar los pesos y la estructura de un modelo de capas convolucionales y re-entrenarlo con unas capas totalmente conectadas en la cima de la red.\n",
    "\n",
    "#### Aplicación\n",
    "\n",
    "Una vez que se tenga la CNN entrenada, se podrá usar la red para el procesamiento de imágenes. Primero tendrá que aprender el estilo de una imagen y aplicarla a otra mientras que la segunda mantiene su estructura (o contenido). Esto será posible si se encuentran los nodos intermedios de la CNN que relacionen al estilo con el contenido de la imagen."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Primero se descargará un modelo pre-entrenado de la red: [http://www.vlfeat.org/matconvnet/models/beta16/imagenet-vgg-verydeep-19.mat](http://www.vlfeat.org/matconvnet/models/beta16/imagenet-vgg-verydeep-19.mat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Luego se cargarán las librerías necesarias:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rogger/anaconda3/lib/python3.6/importlib/_bootstrap.py:205: RuntimeWarning: compiletime version 3.5 of module 'tensorflow.python.framework.fast_tensor_util' does not match runtime version 3.6\n",
      "  return f(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import scipy.misc\n",
    "import scipy.io\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.python.framework import ops\n",
    "ops.reset_default_graph()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se inicia una sesión para el grafo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sess = tf.Session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Imagenes para cargar\n",
    "original_image_file = 'imagenes/book_cover.jpg'\n",
    "style_image_file = 'imagenes/Crash.jpg'\n",
    "\n",
    "# Modelo VGG\n",
    "vgg_path = 'imagenet-vgg-verydeep-19.mat'\n",
    "\n",
    "# Argumentos por defecto\n",
    "original_image_weight = 5.0\n",
    "style_image_weight = 500.0\n",
    "regularization_weight = 100\n",
    "learning_rate = 0.001\n",
    "generations = 500\n",
    "output_generations = 25\n",
    "beta1 = 0.9   # For the Adam optimizer\n",
    "beta2 = 0.999 # For the Adam optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Leer las imagenes\n",
    "original_image = scipy.misc.imread(original_image_file)\n",
    "style_image = scipy.misc.imread(style_image_file)\n",
    "\n",
    "# Obtener el tamaño de la imagen que obtendrá el estilo y cambiar el tamaño de la otra para que ambas tengan el mismo\n",
    "target_shape = original_image.shape\n",
    "style_image = scipy.misc.imresize(style_image, target_shape[1] / style_image.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# VGG-19 Capas\n",
    "# Del paper\n",
    "vgg_layers = ['conv1_1', 'relu1_1',\n",
    "              'conv1_2', 'relu1_2', 'pool1',\n",
    "              'conv2_1', 'relu2_1',\n",
    "              'conv2_2', 'relu2_2', 'pool2',\n",
    "              'conv3_1', 'relu3_1',\n",
    "              'conv3_2', 'relu3_2',\n",
    "              'conv3_3', 'relu3_3',\n",
    "              'conv3_4', 'relu3_4', 'pool3',\n",
    "              'conv4_1', 'relu4_1',\n",
    "              'conv4_2', 'relu4_2',\n",
    "              'conv4_3', 'relu4_3',\n",
    "              'conv4_4', 'relu4_4', 'pool4',\n",
    "              'conv5_1', 'relu5_1',\n",
    "              'conv5_2', 'relu5_2',\n",
    "              'conv5_3', 'relu5_3',\n",
    "              'conv5_4', 'relu5_4']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Se extrae la información del archivo mat\n",
    "def extract_net_info(path_to_params):\n",
    "    vgg_data = scipy.io.loadmat(path_to_params)\n",
    "    normalization_matrix = vgg_data['normalization'][0][0][0]\n",
    "    mat_mean = np.mean(normalization_matrix, axis=(0,1))\n",
    "    network_weights = vgg_data['layers'][0]\n",
    "    return(mat_mean, network_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Se recrea la red\n",
    "def vgg_network(network_weights, init_image):\n",
    "    network = {}\n",
    "    image = init_image\n",
    "\n",
    "    for i, layer in enumerate(vgg_layers):\n",
    "        if layer[0] == 'c':\n",
    "            weights, bias = network_weights[i][0][0][0][0]\n",
    "            weights = np.transpose(weights, (1, 0, 2, 3))\n",
    "            bias = bias.reshape(-1)\n",
    "            conv_layer = tf.nn.conv2d(image, tf.constant(weights), (1, 1, 1, 1), 'SAME')\n",
    "            image = tf.nn.bias_add(conv_layer, bias)\n",
    "        elif layer[0] == 'r':\n",
    "            image = tf.nn.relu(image)\n",
    "        else:\n",
    "            image = tf.nn.max_pool(image, (1, 2, 2, 1), (1, 2, 2, 1), 'SAME')\n",
    "        network[layer] = image\n",
    "    return(network)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "original_layer = 'relu4_2'\n",
    "style_layers = ['relu1_1', 'relu2_1', 'relu3_1', 'relu4_1', 'relu5_1']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "normalization_mean, network_weights = extract_net_info(vgg_path)\n",
    "\n",
    "shape = (1,) + original_image.shape\n",
    "style_shape = (1,) + style_image.shape\n",
    "original_features = {}\n",
    "style_features = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Se recrea la red\n",
    "image = tf.placeholder('float', shape=shape)\n",
    "vgg_net = vgg_network(network_weights, image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Se normaliza la matriz de la imagen y se corre sobre la red\n",
    "original_minus_mean = original_image - normalization_mean\n",
    "original_norm = np.array([original_minus_mean])\n",
    "original_features[original_layer] = sess.run(vgg_net[original_layer], feed_dict={image: original_norm})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Se repite el procedimiento con cada capa de estilo que se escogió antes\n",
    "image = tf.placeholder('float', shape=style_shape)\n",
    "vgg_net = vgg_network(network_weights, image)\n",
    "style_minus_mean = style_image - normalization_mean\n",
    "style_norm = np.array([style_minus_mean])\n",
    "\n",
    "for layer in style_layers:\n",
    "    layer_output = sess.run(vgg_net[layer], feed_dict={image: style_norm})\n",
    "    layer_output = np.reshape(layer_output, (-1, layer_output.shape[3]))\n",
    "    style_gram_matrix = np.matmul(layer_output.T, layer_output) / layer_output.size\n",
    "    style_features[layer] = style_gram_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Para crear la combinación, se agrega ruido a través de la red\n",
    "initial = tf.random_normal(shape) * 0.256\n",
    "image = tf.Variable(initial)\n",
    "vgg_net = vgg_network(network_weights, image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Primera perdida\n",
    "original_loss = original_image_weight * (2 * tf.nn.l2_loss(vgg_net[original_layer] - original_features[original_layer]) /\n",
    "                original_features[original_layer].size)\n",
    "\n",
    "# Perdida en el estilo\n",
    "style_loss = 0\n",
    "style_losses = []\n",
    "for style_layer in style_layers:\n",
    "    layer = vgg_net[style_layer]\n",
    "    feats, height, width, channels = [x.value for x in layer.get_shape()]\n",
    "    size = height * width * channels\n",
    "    features = tf.reshape(layer, (-1, channels))\n",
    "    style_gram_matrix = tf.matmul(tf.transpose(features), features) / size\n",
    "    style_expected = style_features[style_layer]\n",
    "    #style_temp_loss = sess.run(2 * tf.nn.l2_loss(style_gram_matrix - style_expected) / style_expected.size)\n",
    "    #print('Layer: {}, Loss: {}'.format(style_layer, style_temp_loss))\n",
    "    style_losses.append(2 * tf.nn.l2_loss(style_gram_matrix - style_expected) / style_expected.size)\n",
    "style_loss += style_image_weight * tf.reduce_sum(style_losses)\n",
    "\n",
    "# Se calcula la variación total       \n",
    "total_var_x = sess.run(tf.reduce_prod(image[:,1:,:,:].get_shape()))\n",
    "total_var_y = sess.run(tf.reduce_prod(image[:,:,1:,:].get_shape()))\n",
    "first_term = regularization_weight * 2\n",
    "second_term_numerator = tf.nn.l2_loss(image[:,1:,:,:] - image[:,:shape[1]-1,:,:])\n",
    "second_term = second_term_numerator / total_var_y\n",
    "third_term = (tf.nn.l2_loss(image[:,:,1:,:] - image[:,:,:shape[2]-1,:]) / total_var_x)\n",
    "total_variation_loss = first_term * (second_term + third_term)\n",
    "\n",
    "# Se combinan las pérdidas\n",
    "loss = original_loss + style_loss + total_variation_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "style_layer = 'relu2_1'\n",
    "layer = vgg_net[style_layer]\n",
    "feats, height, width, channels = [x.value for x in layer.get_shape()]\n",
    "size = height * width * channels\n",
    "features = tf.reshape(layer, (-1, channels))\n",
    "style_gram_matrix = tf.matmul(tf.transpose(features), features) / size\n",
    "style_expected = style_features[style_layer]\n",
    "style_losses.append(2 * tf.nn.l2_loss(style_gram_matrix - style_expected) / style_expected.size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Declaracion del algoritmo de Optimización\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate, beta1, beta2)\n",
    "train_step = optimizer.minimize(loss)\n",
    "\n",
    "# Inicialización de varibles y comenzar el entrenamiento\n",
    "sess.run(tf.global_variables_initializer())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------Layer: relu1_1 -------\n",
      "[[[[ 0.99769211  0.124571    0.23778097 ...,  1.10440874  0.95318878\n",
      "     1.06157756]\n",
      "   [ 1.35292888  0.09873338  0.13368434 ...,  1.01553416  0.70510364\n",
      "     0.82214618]\n",
      "   [ 0.88811225  0.02323176  0.06103561 ...,  1.06558287  0.61542916\n",
      "     0.61561382]\n",
      "   ..., \n",
      "   [ 0.57664013  0.08556816  0.         ...,  1.16084933  0.59294796\n",
      "     0.33717477]\n",
      "   [ 0.60938329  0.13984084  0.11584599 ...,  1.15865004  0.77761126\n",
      "     0.66960132]\n",
      "   [ 0.88127607  0.10543361  0.02637555 ...,  1.05082774  0.40969166\n",
      "     0.38527912]]\n",
      "\n",
      "  [[ 1.37836874  0.          0.05851355 ...,  1.05180013  0.91608578\n",
      "     0.97667742]\n",
      "   [ 1.25047779  0.          0.         ...,  1.01488149  0.74933147\n",
      "     0.68917441]\n",
      "   [ 0.43000606  0.          0.         ...,  1.00617182  0.65972489\n",
      "     0.46168712]\n",
      "   ..., \n",
      "   [ 0.34920537  0.10079706  0.         ...,  1.09308922  0.157204    0.        ]\n",
      "   [ 0.48915446  0.1032795   0.08191188 ...,  1.16370654  0.67862147\n",
      "     0.54354072]\n",
      "   [ 0.85406595  0.09297816  0.05771028 ...,  1.03626227  0.41501382\n",
      "     0.35357946]]\n",
      "\n",
      "  [[ 0.31624931  0.          0.         ...,  1.04595506  0.          0.        ]\n",
      "   [ 0.          0.          0.         ...,  1.13710606  0.10098413  0.        ]\n",
      "   [ 0.00336903  0.          0.         ...,  0.88094258  0.32219499\n",
      "     0.06188223]\n",
      "   ..., \n",
      "   [ 1.04285014  0.15316252  0.09121951 ...,  1.1245023   0.22519463\n",
      "     0.2477567 ]\n",
      "   [ 0.87015808  0.03818878  0.14265516 ...,  1.24995351  0.72008252\n",
      "     0.68101853]\n",
      "   [ 0.86074364  0.05341803  0.09154966 ...,  1.20927036  0.70673001\n",
      "     0.61456823]]\n",
      "\n",
      "  ..., \n",
      "  [[ 0.78488016  0.097468    0.11504523 ...,  0.98483598  0.4356007\n",
      "     0.43022099]\n",
      "   [ 0.63939977  0.05522929  0.         ...,  0.92303884  0.          0.        ]\n",
      "   [ 0.          0.          0.         ...,  0.92971444  0.40519068\n",
      "     0.02376395]\n",
      "   ..., \n",
      "   [ 0.69549096  0.17744908  0.09999846 ...,  0.7274074   0.31690979\n",
      "     0.29494536]\n",
      "   [ 0.76295078  0.21391374  0.21333379 ...,  1.03678966  0.29531899\n",
      "     0.42941046]\n",
      "   [ 0.89901936  0.11321595  0.05890916 ...,  1.01408565  0.05942956\n",
      "     0.12781093]]\n",
      "\n",
      "  [[ 1.03997874  0.21730351  0.2368996  ...,  1.21707642  0.67882025\n",
      "     0.74917817]\n",
      "   [ 0.80270553  0.20190129  0.1975427  ...,  1.192011    0.56154954\n",
      "     0.42207748]\n",
      "   [ 0.20268762  0.02159877  0.20577712 ...,  1.03221858  0.9226898\n",
      "     0.67496204]\n",
      "   ..., \n",
      "   [ 0.87911397  0.24171382  0.13805893 ...,  0.68263054  0.74040878\n",
      "     0.56829655]\n",
      "   [ 1.42172039  0.27878585  0.33460757 ...,  0.88098323  1.04020286\n",
      "     1.24563789]\n",
      "   [ 1.58550549  0.17495725  0.05886561 ...,  0.85790086  0.27079615\n",
      "     0.35615051]]\n",
      "\n",
      "  [[ 0.92304474  0.1519708   0.08326285 ...,  1.04874647  0.52650678\n",
      "     0.46073627]\n",
      "   [ 0.81592435  0.14831147  0.09193242 ...,  1.00382745  0.61940718\n",
      "     0.43299386]\n",
      "   [ 0.66143364  0.07305861  0.17253283 ...,  0.96211123  0.96204889\n",
      "     0.73753703]\n",
      "   ..., \n",
      "   [ 1.04926753  0.19953626  0.06392978 ...,  0.84567195  0.57365179\n",
      "     0.48794755]\n",
      "   [ 1.00931501  0.22531801  0.11027719 ...,  1.02971387  0.67552716\n",
      "     0.71513492]\n",
      "   [ 0.97705424  0.15763515  0.         ...,  0.98272848  0.28573328\n",
      "     0.23479347]]]]\n",
      "9555712\n",
      "\n",
      "-------Layer: relu2_1 -------\n",
      "[[[[  0.           0.           0.         ...,   7.19698811   0.\n",
      "     11.77770329]\n",
      "   [  0.           1.23748016   0.         ...,   3.80043221   0.\n",
      "     15.69626617]\n",
      "   [  0.           1.49514818   0.         ...,   3.60039186   0.\n",
      "     14.09841251]\n",
      "   ..., \n",
      "   [  0.           2.3132081    0.         ...,   5.18848562   0.\n",
      "     14.6943779 ]\n",
      "   [  0.           0.47924784   0.         ...,   3.46707678   0.\n",
      "     13.46106052]\n",
      "   [  0.           1.37931097   0.         ...,   7.44524431   0.\n",
      "      9.15576458]]\n",
      "\n",
      "  [[  0.           0.           0.         ...,   3.26449394   0.\n",
      "      1.5202738 ]\n",
      "   [  0.           0.66188532   0.         ...,   3.24447584   1.59707582\n",
      "      0.74851626]\n",
      "   [  0.           1.58801985   0.         ...,   5.268538     3.57823372\n",
      "      2.48880029]\n",
      "   ..., \n",
      "   [  0.           2.15447712   0.         ...,   4.17157936   0.\n",
      "      2.4135735 ]\n",
      "   [  0.           1.44892848   0.         ...,   5.00422287   0.\n",
      "      2.4559195 ]\n",
      "   [  0.           1.73300362   0.         ...,   3.06642199   0.\n",
      "      2.90959954]]\n",
      "\n",
      "  [[  0.           0.           0.56163764 ...,   5.11066151   0.\n",
      "      0.50882453]\n",
      "   [  0.           0.5535304    0.         ...,   4.28973389   0.           0.        ]\n",
      "   [  0.           2.00719118   0.         ...,   4.70996666   0.\n",
      "      0.7901842 ]\n",
      "   ..., \n",
      "   [  0.           0.           2.45032477 ...,   6.75664902   0.\n",
      "      2.51373792]\n",
      "   [  0.           1.26881099   0.         ...,   7.45087433   0.\n",
      "      2.8085711 ]\n",
      "   [  0.           3.90690827   0.         ...,   6.92627048   1.21052945\n",
      "      1.75645316]]\n",
      "\n",
      "  ..., \n",
      "  [[  0.           0.           0.         ...,   4.66184902   0.\n",
      "      2.42712712]\n",
      "   [  0.           0.           0.         ...,   3.81110764   0.\n",
      "      2.02109361]\n",
      "   [  0.           2.18809772   0.         ...,   2.04362726   0.26281339\n",
      "      1.96727669]\n",
      "   ..., \n",
      "   [  0.           0.           0.         ...,   4.0243082    0.\n",
      "      2.34731603]\n",
      "   [  0.           2.68345857   0.         ...,   3.1852603    0.\n",
      "      2.08549714]\n",
      "   [  0.           2.09558344   0.         ...,   4.35672951   0.\n",
      "      1.58749211]]\n",
      "\n",
      "  [[  0.           0.           0.55295849 ...,   6.21355915   0.\n",
      "      1.58567297]\n",
      "   [  0.           0.18850771   0.         ...,   4.27294779   0.\n",
      "      2.42907929]\n",
      "   [  0.           2.7852211    0.2991564  ...,   6.56904459   2.17513657\n",
      "      2.82098317]\n",
      "   ..., \n",
      "   [  0.           0.           0.         ...,   1.64325559   0.\n",
      "      2.32379556]\n",
      "   [  0.           2.81917262   0.         ...,   5.71630049   0.\n",
      "      2.88884664]\n",
      "   [  0.           3.29589415   0.         ...,   7.05996799   2.33544517\n",
      "      2.28443885]]\n",
      "\n",
      "  [[  0.           0.           3.321033   ...,   5.76277828   0.81609583\n",
      "      0.        ]\n",
      "   [  0.           0.22154039   5.69140196 ...,  11.3153801    2.35689139\n",
      "      0.        ]\n",
      "   [  0.           1.93162143   6.01212311 ...,   4.29240465   3.62130523\n",
      "      0.        ]\n",
      "   ..., \n",
      "   [  0.           0.           1.94186354 ...,   9.24523163   3.07909346\n",
      "      0.        ]\n",
      "   [  0.           1.41067874   4.63331175 ...,   8.35068035   3.5881741\n",
      "      0.        ]\n",
      "   [  0.           2.63924122   4.6781168  ...,   5.81436586   0.78688323\n",
      "      0.        ]]]]\n",
      "4777856\n",
      "\n",
      "-------Layer: relu3_1 -------\n",
      "[[[[  0.           0.46462056   0.         ...,   1.13209152   9.25867748\n",
      "     16.24217606]\n",
      "   [  0.14215982   5.2165494    2.9276278  ...,   2.04662323  16.23939323\n",
      "     10.49228001]\n",
      "   [  3.82124496  11.21178341   0.60532433 ...,   4.00975895  13.30394459\n",
      "      6.77145576]\n",
      "   ..., \n",
      "   [  1.03274858   0.           0.88488358 ...,   0.           8.69841862\n",
      "      9.92968941]\n",
      "   [  1.20205033   1.29048765   0.44947413 ...,   0.          10.87148762\n",
      "      7.79418516]\n",
      "   [  0.           1.47854912   0.         ...,   0.          11.47331429\n",
      "      3.33815646]]\n",
      "\n",
      "  [[  0.           0.           0.         ...,   0.85742182   0.\n",
      "     15.72225475]\n",
      "   [  0.           0.54410309   1.64846528 ...,   2.59795189   5.9961133\n",
      "      6.5784502 ]\n",
      "   [  3.77280307   5.63875961   0.         ...,   4.8109107    4.69339609\n",
      "      2.58558679]\n",
      "   ..., \n",
      "   [  2.57199121   0.           1.22094834 ...,   0.58762264   4.84175014\n",
      "      6.0122366 ]\n",
      "   [  3.67754412   0.           2.5441339  ...,   0.91691679   9.83558464\n",
      "      3.56402707]\n",
      "   [  1.88756859   0.48093316   0.         ...,   0.          14.76331806\n",
      "      0.49762613]]\n",
      "\n",
      "  [[  0.           0.20190735   0.         ...,   0.35874826   0.\n",
      "     15.4129467 ]\n",
      "   [  0.           0.           1.06357694 ...,   2.47163248   4.33292246\n",
      "      6.32516527]\n",
      "   [  1.69820201   0.           0.         ...,   2.12176132   8.66897869\n",
      "      5.99273872]\n",
      "   ..., \n",
      "   [  6.09884262   0.           0.         ...,   0.           3.16813421\n",
      "      6.81792831]\n",
      "   [  5.63051748   0.           0.36503109 ...,   0.           7.2257843\n",
      "      3.55691838]\n",
      "   [  3.25785446   0.39294896   0.         ...,   0.          13.7473917\n",
      "      0.        ]]\n",
      "\n",
      "  ..., \n",
      "  [[  1.02951705   0.           0.         ...,   0.           0.\n",
      "     15.06882858]\n",
      "   [  5.37872458   0.           3.74915719 ...,   0.56196612   0.\n",
      "      4.14330578]\n",
      "   [  0.           0.           1.02354872 ...,   4.2078371    4.06593084\n",
      "      6.59842491]\n",
      "   ..., \n",
      "   [  2.26557398   0.           0.         ...,   0.          13.60922909\n",
      "      5.00785542]\n",
      "   [  5.21149158   0.           0.         ...,   0.          20.90379524\n",
      "      0.44828278]\n",
      "   [  3.04385042   0.           0.         ...,   0.          12.63389587\n",
      "      0.60385352]]\n",
      "\n",
      "  [[  0.           0.           0.         ...,   0.           0.\n",
      "     14.48444653]\n",
      "   [  0.           0.           2.93058515 ...,   0.           0.\n",
      "      3.79864192]\n",
      "   [  0.           0.09778794   1.83190644 ...,   2.27574396   0.\n",
      "      4.28029442]\n",
      "   ..., \n",
      "   [  3.74220753   0.           0.         ...,   0.           1.98731887\n",
      "      4.84009552]\n",
      "   [  6.03936481   0.           0.         ...,   0.          10.474967\n",
      "      1.44574165]\n",
      "   [  3.19403815   1.58314872   0.         ...,   0.           9.28932762\n",
      "      0.59359777]]\n",
      "\n",
      "  [[  0.           0.           0.         ...,   0.           0.\n",
      "     13.51577377]\n",
      "   [  0.           0.           1.21345878 ...,   2.76250315   0.\n",
      "      9.37835407]\n",
      "   [  0.           1.79034185   4.08207369 ...,   2.73494387   0.\n",
      "      8.55125237]\n",
      "   ..., \n",
      "   [  0.           0.           2.81682086 ...,   0.           0.\n",
      "      9.52027225]\n",
      "   [  0.           0.71757799   2.05284595 ...,   0.79224354   0.\n",
      "      6.67144775]\n",
      "   [  0.           2.57225204   0.         ...,   1.44744456   0.66864115\n",
      "      3.47238278]]]]\n",
      "2414080\n",
      "\n",
      "-------Layer: relu4_1 -------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[[  6.56107855  10.50358582   0.         ...,   0.          45.85224915\n",
      "      0.14670382]\n",
      "   [  8.89608765  13.018363     0.         ...,   0.          16.65531921\n",
      "      6.33728981]\n",
      "   [  6.95187998   7.90370703   0.         ...,   0.           4.3931694\n",
      "     11.6180315 ]\n",
      "   ..., \n",
      "   [  3.5654788   16.57735825   0.         ...,   0.          29.97684097\n",
      "     12.9567852 ]\n",
      "   [  9.40552235  27.66011429   0.         ...,   0.           0.\n",
      "     12.60405636]\n",
      "   [ 10.26278591  28.83856964   2.77758193 ...,   0.           0.\n",
      "     22.41108513]]\n",
      "\n",
      "  [[  0.05949891  15.61852741   0.         ...,   0.          52.58604813\n",
      "      0.        ]\n",
      "   [  0.          22.69583702   3.55708003 ...,   0.          11.73867989\n",
      "      0.        ]\n",
      "   [ 10.39736557  19.79232025   0.         ...,   0.           8.2525816\n",
      "      0.        ]\n",
      "   ..., \n",
      "   [  6.18919468  30.29744148   0.         ...,   0.          28.1273098\n",
      "      0.        ]\n",
      "   [  0.          48.10041046   0.         ...,   0.           0.           0.        ]\n",
      "   [  0.          51.15629578  23.22931671 ...,   0.           0.\n",
      "     21.52461624]]\n",
      "\n",
      "  [[ 16.0749855   13.39836025   0.         ...,   0.          50.62129593\n",
      "      0.        ]\n",
      "   [  0.          24.79256058   2.28022408 ...,   0.          26.72128105\n",
      "      0.        ]\n",
      "   [  0.          27.14975739   0.         ...,   0.          23.27437019\n",
      "      0.        ]\n",
      "   ..., \n",
      "   [  0.          31.21929169   0.         ...,   0.          20.98668289\n",
      "      0.        ]\n",
      "   [  0.          48.14125061   0.         ...,   0.           0.           0.        ]\n",
      "   [  0.          50.03248596  22.67469215 ...,   0.           0.\n",
      "     20.66038132]]\n",
      "\n",
      "  ..., \n",
      "  [[  0.          24.09000397   0.         ...,   0.          52.30524063\n",
      "      0.        ]\n",
      "   [  0.          41.31375122  14.91920376 ...,   0.          17.45038795\n",
      "      0.        ]\n",
      "   [  0.          36.53589249   8.18435574 ...,   0.          18.72810364\n",
      "      0.        ]\n",
      "   ..., \n",
      "   [  0.          36.6714325    0.         ...,   0.          25.2502861\n",
      "      0.        ]\n",
      "   [  0.          52.47919083   0.         ...,   0.           0.           0.        ]\n",
      "   [  0.          45.08979416  22.11067772 ...,   0.           0.\n",
      "     24.97355652]]\n",
      "\n",
      "  [[  2.89398456  14.72592163   0.         ...,   0.          40.48067093\n",
      "      0.        ]\n",
      "   [  0.          34.01504517  12.75809765 ...,   0.           7.83287144\n",
      "      0.        ]\n",
      "   [  0.          29.68654823   3.03052592 ...,   0.          26.92415047\n",
      "      0.        ]\n",
      "   ..., \n",
      "   [  0.          27.13988686   0.         ...,   0.          21.56267166\n",
      "      0.        ]\n",
      "   [  0.          44.69786072   0.         ...,   0.           0.           0.        ]\n",
      "   [  0.          44.06175613  18.37053108 ...,   0.           0.\n",
      "     19.25400352]]\n",
      "\n",
      "  [[ 17.67381859   8.23663139  12.76261616 ...,   0.          30.95267868\n",
      "      0.        ]\n",
      "   [  0.          24.9092083   28.48385429 ...,   0.           4.20544195\n",
      "      0.        ]\n",
      "   [  7.3055501   22.60157585  24.70147896 ...,   0.          22.56798553\n",
      "      0.        ]\n",
      "   ..., \n",
      "   [  0.          19.06836891   0.77343035 ...,   0.          21.27654076\n",
      "      0.        ]\n",
      "   [  3.22432017  28.12791061  11.48814774 ...,   0.           7.81025553\n",
      "      0.63297236]\n",
      "   [  0.26067561  31.19150162  22.24400902 ...,   0.           0.\n",
      "     11.7091217 ]]]]\n",
      "1217536\n",
      "\n",
      "-------Layer: relu5_1 -------\n",
      "[[[[ 0.69413334  0.          3.17617798 ...,  1.6469897   0.          0.        ]\n",
      "   [ 0.70107776  0.          1.5753442  ...,  0.48147416  0.          0.        ]\n",
      "   [ 0.83999836  0.          0.         ...,  0.34668377  0.          0.        ]\n",
      "   ..., \n",
      "   [ 0.          0.          1.78275418 ...,  0.17311941  0.          0.        ]\n",
      "   [ 0.          0.          4.50339317 ...,  0.          0.          0.        ]\n",
      "   [ 2.23357773  0.          4.17611456 ...,  0.          0.          0.        ]]\n",
      "\n",
      "  [[ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      "   [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      "   [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      "   ..., \n",
      "   [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      "   [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      "   [ 1.59384131  0.          0.         ...,  0.          0.          0.        ]]\n",
      "\n",
      "  [[ 0.          0.          0.         ...,  0.10202028  0.          0.        ]\n",
      "   [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      "   [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      "   ..., \n",
      "   [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      "   [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      "   [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "\n",
      "  ..., \n",
      "  [[ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      "   [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      "   [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      "   ..., \n",
      "   [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      "   [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      "   [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "\n",
      "  [[ 0.          0.          0.         ...,  1.68003869  0.          0.        ]\n",
      "   [ 0.          0.          0.         ...,  0.47923842  0.          0.        ]\n",
      "   [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      "   ..., \n",
      "   [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      "   [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      "   [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "\n",
      "  [[ 0.          0.          0.         ...,  0.45083189  0.          0.        ]\n",
      "   [ 0.          0.          0.         ...,  0.83573508  0.          0.        ]\n",
      "   [ 0.          0.          0.         ...,  0.08784604  0.          0.        ]\n",
      "   ..., \n",
      "   [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      "   [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      "   [ 0.          0.          0.         ...,  0.          0.          0.        ]]]]\n",
      "311808\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for style_layer in style_layers:\n",
    "    print('-------Layer: {} -------'.format(style_layer))\n",
    "    layer = vgg_net[style_layer]\n",
    "    print(sess.run(layer))\n",
    "    feats, height, width, channels = [x.value for x in layer.get_shape()]\n",
    "    size = height * width * channels\n",
    "    print(size)\n",
    "    print('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generacion  0\n",
      "generacion  1\n",
      "Generation 2 out of 10, loss: 310105984.0\n",
      "generacion  2\n",
      "generacion  3\n",
      "Generation 4 out of 10, loss: 310080288.0\n",
      "generacion  4\n",
      "generacion  5\n",
      "Generation 6 out of 10, loss: 310050240.0\n",
      "generacion  6\n",
      "generacion  7\n",
      "Generation 8 out of 10, loss: 310015040.0\n",
      "generacion  8\n",
      "generacion  9\n",
      "Generation 10 out of 10, loss: 309973472.0\n"
     ]
    }
   ],
   "source": [
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate)\n",
    "train_step = optimizer.minimize(loss)\n",
    "\n",
    "sess.run(tf.global_variables_initializer())\n",
    "for i in range(generations):\n",
    "    print(\"generacion \", i)\n",
    "    sess.run(train_step)\n",
    "\n",
    "    # Imprimir las actulizaciones y guardar imágenes temporales\n",
    "    if (i+1) % output_generations == 0:\n",
    "        print('Generation {} out of {}, loss: {}'.format(i + 1, generations,sess.run(loss)))\n",
    "        image_eval = sess.run(image)\n",
    "        best_image_add_mean = image_eval.reshape(shape[1:]) + normalization_mean\n",
    "        output_file = 'temp_output_{}.jpg'.format(i)\n",
    "        scipy.misc.imsave(output_file, best_image_add_mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "image_eval = sess.run(image)\n",
    "best_image_add_mean = image_eval.reshape(shape[1:]) + normalization_mean\n",
    "output_file = 'final_output.jpg'\n",
    "scipy.misc.imsave(output_file, best_image_add_mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
